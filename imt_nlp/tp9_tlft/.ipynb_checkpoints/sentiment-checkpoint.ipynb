{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/adeshpande3/LSTM-Sentiment-Analysis\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = open('./data/imdb_master.txt', 'r')\n",
    "out = open('./data/imdb_master_lemma.txt', 'w')\n",
    "\n",
    "limit, count, t,sentifile, temp_t = 1, 0, None, '', None\n",
    "\n",
    "for line in inp:\n",
    "    #count += 1\n",
    "    #if limit < count: break\n",
    "    t = line[-4:-1]\n",
    "    review = line[:-5]\n",
    "    doc = nlp(review)\n",
    "    if t != temp_t: print(f'DEBUT DOCUMENT {t}', file=out)\n",
    "    temp_t = t\n",
    "    for sent in doc.sents:\n",
    "        print('DEBUT PHRASE', file=out)\n",
    "        for token in sent:\n",
    "            l = (token.i, token.text, token.lemma_, token.tag_, token.head.i, token.dep_)\n",
    "            s = '\\t'.join([str(e) for e in l])\n",
    "            print(f'{s}', file=out)\n",
    "            #print(s)\n",
    "        print('FIN PHRASE')\n",
    "    print('FIN DOCUMENT')\n",
    "\n",
    "inp.close()\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, pickle, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentifile = open('./data/SentiWordNet_3.0.0.txt', 'r')\n",
    "\n",
    "re_sentiline = re.compile(r'^([avn])\\t([\\d]+)\\t([\\d\\.]+)\\t([\\d\\.]+)\\t([^\\t]+)\\t')\n",
    "re_sentimots = re.compile(r'([a-z-]+)#([0-9]+)')\n",
    "\n",
    "SENTI = {}\n",
    "limit, count = 100, 0\n",
    "for line in sentifile:\n",
    "    res = re_sentiline.match(line)\n",
    "    count += 1\n",
    "    #if not line[0] == 'a': continue\n",
    "    #if limit < count: break\n",
    "    if not res: continue    \n",
    "    pos = float(res.group(3))\n",
    "    neg = float(res.group(4))\n",
    "    res2 = re_sentimots.findall(res.group(5))\n",
    "    for m in res2:\n",
    "        if m[1] == '1':\n",
    "            if pos == 0 and neg == 0:\n",
    "                SENTI[m[0]] = (0, 0, 0)\n",
    "            else :\n",
    "                SENTI[m[0]] = (pos, neg, pos/(pos+neg))\n",
    "                \n",
    "out=open(\"./data/SentiWordNet.pickle\",\"wb\")\n",
    "pickle.dump(SENTI,out)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilnp = open('./data/imdb_master_lemma.txt')\n",
    "picklefile = open(\"./data/SentiWordNet.pickle\",\"rb\")\n",
    "SENTI = pickle.load(picklefile)\n",
    "picklefile.close()\n",
    "\n",
    "re_lemma = re.compile(r\"^([\\d]+)\\s([\\w\\.\\,\\'-?\\(\\)!\\\"`%&]+)\\s([\\w\\.\\,\\-\\'-?\\(\\)!\\\"`%& ]+)\\s([\\w\\.\\,$:\\-\\'`_]+)\\s([\\d]+)\\s([\\w]+)\")\n",
    "limit, count, ty, temp_ty = 1000, 0, None, None\n",
    "corpus_val, corpus_class, a = list(), list(), list()\n",
    "for line in ilnp:\n",
    "    count += 1\n",
    "    #if limit < count: break\n",
    "    m = re.match(r'DEBUT DOCUMENT ([\\w]+)', line)\n",
    "    if m : \n",
    "        ty = m.group(1)\n",
    "        a = []\n",
    "        continue\n",
    "    m = re.match(r'DEBUT PHRASE', line)\n",
    "    if m: continue\n",
    "    m = re.match(r'FIN PHRASE', line)\n",
    "    if m: continue\n",
    "    m = re.match(r'FIN DOCUMENT', line)\n",
    "    if m: \n",
    "        if (len(a)>0):\n",
    "            avg=sum(a)/len(a)\n",
    "        else:\n",
    "            avg=0\n",
    "            corpus_val.append([avg])\n",
    "            corpus_class.append(ty)\n",
    "    m = re_lemma.match(line)\n",
    "    if not m: continue\n",
    "    lemma = m.group(3)\n",
    "    if lemma in SENTI: \n",
    "        a.append(SENTI[lemma][2])\n",
    "        # making an error => The appending should happen by review/sentiment, not by avery single found lemma\n",
    "        #corpus_val.append(SENTI[lemma][2]) # sentiment append\n",
    "        #corpus_class.append(ty)        \n",
    "ilnp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(l, class_assign):\n",
    "    cl = np.unique(corpus_class)\n",
    "    d = { c: ca for i, (c, ca) in enumerate(zip(cl, class_assign)) }\n",
    "    return [ d[c] for c in l ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_class_oh = oneHot(corpus_class, [-1, 1])\n",
    "corpus_val, corpus_class_oh = shuffle(corpus_val, corpus_class_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-classes accuracy: 0.50 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, corpus_val, corpus_class_oh, cv=5, n_jobs=5)\n",
    "print(\"Two-classes accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilnp = open('./data/imdb_master_lemma.txt')\n",
    "picklefile = open(\"./data/SentiWordNet.pickle\",\"rb\")\n",
    "SENTI = pickle.load(picklefile)\n",
    "picklefile.close()\n",
    "\n",
    "re_lemma = re.compile(r\"^([\\d]+)\\s([\\w\\.\\,\\'-?\\(\\)!\\\"`%&]+)\\s([\\w\\.\\,\\-\\'-?\\(\\)!\\\"`%& ]+)\\s([\\w\\.\\,$:\\-\\'`_]+)\\s([\\d]+)\\s([\\w]+)\")\n",
    "limit, count, ty, temp_ty = 1000, 0, None, None\n",
    "corpus_val, corpus_class, a = list(), list(), list()\n",
    "for line in ilnp:\n",
    "    count += 1\n",
    "    #if limit < count: break\n",
    "    m = re.match(r'DEBUT DOCUMENT ([\\w]+)', line)\n",
    "    if m : \n",
    "        ty = m.group(1)\n",
    "        a = []\n",
    "        continue\n",
    "    m = re.match(r'DEBUT PHRASE', line)\n",
    "    if m: continue\n",
    "    m = re.match(r'FIN PHRASE', line)\n",
    "    if m: continue\n",
    "    m = re.match(r'FIN DOCUMENT', line)\n",
    "    if m: \n",
    "        if (len(a)>0):\n",
    "            avg=sum(a)/len(a)\n",
    "        else:\n",
    "            avg=0\n",
    "            corpus_val.append([avg])\n",
    "            corpus_class.append(ty)\n",
    "    m = re_lemma.match(line)\n",
    "    if not m: continue\n",
    "    lemma, depnat = m.group(3), m.group(5)\n",
    "    if lemma in SENTI and depnat=='ROOT': \n",
    "        a.append(SENTI[lemma][2])  \n",
    "ilnp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-classes accuracy: 0.50 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "corpus_class_oh = oneHot(corpus_class, [-1, 1])\n",
    "corpus_val, corpus_class_oh = shuffle(corpus_val, corpus_class_oh)\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, corpus_val, corpus_class_oh, cv=5, n_jobs=5)\n",
    "print(\"Two-classes accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bita6748a10fd904a55b24d331e21814786"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

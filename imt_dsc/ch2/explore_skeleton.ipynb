{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_method(graph, empty, attr):\n",
    "    \"\"\"   Predict the missing attribute with a simple but effective\n",
    "    relational classifier. \n",
    "    \n",
    "    The assumption is that two connected nodes are \n",
    "    likely to share the same attribute value. Here we chose the most frequently\n",
    "    used attribute by the neighbors\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : graph\n",
    "       A networkx graph\n",
    "    empty : list\n",
    "       The nodes with empty attributes \n",
    "    attr : dict \n",
    "       A dict of attributes, either location, employer or college attributes. \n",
    "       key is a node, value is a list of attribute values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predicted_values : dict \n",
    "       A dict of attributes, either location, employer or college attributes. \n",
    "       key is a node (from empty), value is a list of attribute values. Here \n",
    "       only 1 value in the list.\n",
    "     \"\"\"\n",
    "    predicted_values={}\n",
    "    for n in empty:\n",
    "        nbrs_attr_values=[] \n",
    "        for nbr in graph.neighbors(n):\n",
    "            if nbr in attr:\n",
    "                for val in attr[nbr]:\n",
    "                    nbrs_attr_values.append(val)\n",
    "        predicted_values[n]=[]\n",
    "        if nbrs_attr_values: # non empty list\n",
    "            # count the number of occurrence each value and returns a dict\n",
    "            cpt=Counter(nbrs_attr_values)\n",
    "            # take the most represented attribute value among neighbors\n",
    "            a,nb_occurrence=max(cpt.items(), key=lambda t: t[1])\n",
    "            predicted_values[n].append(a)\n",
    "    return predicted_values\n",
    "    \n",
    " \n",
    "def evaluation_accuracy(groundtruth, pred):\n",
    "    \"\"\"    Compute the accuracy of your model.\n",
    "\n",
    "     The accuracy is the proportion of true results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    groundtruth :  : dict \n",
    "       A dict of attributes, either location, employer or college attributes. \n",
    "       key is a node, value is a list of attribute values.\n",
    "    pred : dict \n",
    "       A dict of attributes, either location, employer or college attributes. \n",
    "       key is a node, value is a list of attribute values. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : float\n",
    "       Accuracy.\n",
    "    \"\"\"\n",
    "    true_positive_prediction=0   \n",
    "    for p_key, p_value in pred.items():\n",
    "        if p_key in groundtruth:\n",
    "            # if prediction is no attribute values, e.g. [] and so is the groundtruth\n",
    "            # May happen\n",
    "            if not p_value and not groundtruth[p_key]:\n",
    "                true_positive_prediction+=1\n",
    "            # counts the number of good prediction for node p_key\n",
    "            # here len(p_value)=1 but we could have tried to predict more values\n",
    "            true_positive_prediction += len([c for c in p_value if c in groundtruth[p_key]])          \n",
    "        # no else, should not happen: train and test datasets are consistent\n",
    "    return true_positive_prediction*100/sum(len(v) for v in pred.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of users in our graph: 811\n",
      "Nb of users with one or more attribute college: 230\n",
      "Nb of users with one or more attribute location: 336\n",
      "Nb of users with one or more attribute employer: 297\n",
      "Your mission, find attributes to 475 users with empty profile\n",
      "19.696970% of the predictions are true\n",
      "Very poor result!!! Try to do better!!!!\n"
     ]
    }
   ],
   "source": [
    "# load the graph\n",
    "G = nx.read_gexf(data_dir + \"mediumLinkedin.gexf\")\n",
    "print(\"Nb of users in our graph: %d\" % len(G))\n",
    "\n",
    "# load the profiles. 3 files for each type of attribute\n",
    "# Some nodes in G have no attributes\n",
    "# Some nodes may have 1 attribute 'location'\n",
    "# Some nodes may have 1 or more 'colleges' or 'employers', so we\n",
    "# use dictionaries to store the attributes\n",
    "college={}\n",
    "location={}\n",
    "employer={}\n",
    "# The dictionaries are loaded as dictionaries from the disk (see pickle in Python doc)\n",
    "with open(data_dir + 'mediumCollege_60percent_of_empty_profile.pickle', 'rb') as handle:\n",
    "    college = pickle.load(handle)\n",
    "with open(data_dir + 'mediumLocation_60percent_of_empty_profile.pickle', 'rb') as handle:\n",
    "    location = pickle.load(handle)\n",
    "with open(data_dir + 'mediumEmployer_60percent_of_empty_profile.pickle', 'rb') as handle:\n",
    "    employer = pickle.load(handle)\n",
    "\n",
    "print(\"Nb of users with one or more attribute college: %d\" % len(college))\n",
    "print(\"Nb of users with one or more attribute location: %d\" % len(location))\n",
    "print(\"Nb of users with one or more attribute employer: %d\" % len(employer))\n",
    "\n",
    "# here are the empty nodes for whom your challenge is to find the profiles\n",
    "empty_nodes=[]\n",
    "with open(data_dir + 'mediumRemovedNodes_60percent_of_empty_profile.pickle', 'rb') as handle:\n",
    "    empty_nodes = pickle.load(handle)\n",
    "print(\"Your mission, find attributes to %d users with empty profile\" % len(empty_nodes))\n",
    "\n",
    "\n",
    "# --------------------- Baseline method -------------------------------------#\n",
    "# Try a naive method to predict attribute\n",
    "# This will be a baseline method for you, i.e. you will compare your performance\n",
    "# with this method\n",
    "# Let's try with the attribute 'employer'\n",
    "employer_predictions=naive_method(G, empty_nodes, employer)\n",
    "groundtruth_employer={}\n",
    "with open(data_dir + 'mediumEmployer.pickle', 'rb') as handle:\n",
    "    groundtruth_employer = pickle.load(handle)\n",
    "result=evaluation_accuracy(groundtruth_employer,employer_predictions)\n",
    "print(\"%f%% of the predictions are true\" % result)\n",
    "print(\"Very poor result!!! Try to do better!!!!\")\n",
    "\n",
    "# --------------------- Now your turn -------------------------------------#\n",
    "# Explore, implement your strategy to fill empty profiles of empty_nodes\n",
    "\n",
    "\n",
    "# and compare with the ground truth (what you should have predicted)\n",
    "# user precision and recall measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

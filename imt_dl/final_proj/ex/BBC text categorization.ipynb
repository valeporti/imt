{"cells":[{"metadata":{"id":"ZCXNyqFq7vY8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"ec7dfb3c-88e1-478b-ec4a-08a667fa5698","executionInfo":{"status":"ok","timestamp":1529968185252,"user_tz":240,"elapsed":2118,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"6e33d72836cf1df501fe5c7d4df38f8131b72b80"},"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# print(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nimport itertools\nimport os\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow import keras\nlayers = keras.layers\nmodels = keras.models\n\n\n# This code was tested with TensorFlow v1.8\nprint(\"You have TensorFlow version\", tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"id":"m6si-xluXrW6","colab_type":"text","_uuid":"1a068e9906a1b8c0fc8fc3145b064467135a212f"},"cell_type":"markdown","source":"## Get the data\nThe data has been exported from BigQuery and is stored on GCS, and can be access directly via \n\n  `!gsutil cp gs://dataset-uploader/bbc/bbc-text.csv .`\n\nIt can also be accessed via https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv "},{"metadata":{"id":"PBJ8CTYL7vZD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"f0cb9078-369b-4f39-d1b5-a2bb4936a392","executionInfo":{"status":"ok","timestamp":1529968248939,"user_tz":240,"elapsed":891,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"3def70f0527177e1e6fdfd024b79804402e9c088"},"cell_type":"code","source":"data = pd.read_csv(\"../input/bbc-text.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"CBtXsyqr7vZG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":204},"outputId":"91407087-b090-414d-8c18-acae82d9a26e","executionInfo":{"status":"ok","timestamp":1529968252342,"user_tz":240,"elapsed":253,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"6e09deecd8c20bb3bd2bb792b0622f6d128410d0"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"CUw2hqtv7vZK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":119},"outputId":"609cf652-d7d3-4d3c-bd0b-3457a1d891c7","executionInfo":{"status":"ok","timestamp":1529968259350,"user_tz":240,"elapsed":239,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"483f40036cdc496a43796b88046874c12c19cb76"},"cell_type":"code","source":"data['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"Ilatvz9j7vZN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"44f66230-f029-4008-c1fb-c9c705a6e0ae","executionInfo":{"status":"ok","timestamp":1529968288460,"user_tz":240,"elapsed":432,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"bda23ce14c9e6cc07d459ce4f3295dcacfeb88a9"},"cell_type":"code","source":"train_size = int(len(data) * .8)\nprint (\"Train size: %d\" % train_size)\nprint (\"Test size: %d\" % (len(data) - train_size))","execution_count":null,"outputs":[]},{"metadata":{"id":"_WiJBv3E7vZQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"0b13b71e-f63b-4211-d5c4-d8b99a4b0d01","executionInfo":{"status":"ok","timestamp":1529968332817,"user_tz":240,"elapsed":261,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"6073c1614a697e0bc09c64e8140228d8e9ccd07c"},"cell_type":"code","source":"def train_test_split(data, train_size):\n    train = data[:train_size]\n    test = data[train_size:]\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"id":"5u6HXfm_ciaR","colab_type":"text","_uuid":"58e07108e5cb00de0e0a274b2225aa8834c43393"},"cell_type":"markdown","source":"## Data preparation\nThere's some work to be done in order for our data to be ready for training.\n1. First we'll split the data into training and test sets.\n1. Then we'll tokenize the words (text), and then convert them to a numbered index. \n1. Next we'll do the same for the labels (categories), by using the `LabelEncoder` utility.\n1. Finally, we'll convert the labels to a one-hot representation."},{"metadata":{"id":"7gs0Skc67vZU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"36190a1a-8fc5-4dc0-fe28-a8c230372625","executionInfo":{"status":"ok","timestamp":1529968339164,"user_tz":240,"elapsed":250,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"4e83f69f4762d5b64929e06c071989456572ee21"},"cell_type":"code","source":"train_cat, test_cat = train_test_split(data['category'], train_size)\ntrain_text, test_text = train_test_split(data['text'], train_size)","execution_count":null,"outputs":[]},{"metadata":{"id":"ujAGiFCy7vZW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"5a276274-4fd6-4812-b417-f50747c1060a","executionInfo":{"status":"ok","timestamp":1529968392523,"user_tz":240,"elapsed":349,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"6dc3604d80e5eccadba1e8a9f54d779bf915015f"},"cell_type":"code","source":"max_words = 1000\ntokenize = keras.preprocessing.text.Tokenizer(num_words=max_words, \n                                              char_level=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"Fc384gXv7vZY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"a2644f11-121b-4287-be3b-58e8d4b79448","executionInfo":{"status":"ok","timestamp":1529968412683,"user_tz":240,"elapsed":1734,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"c6f639eb0d6196ea9b1f0c5605913a47206a4f1e"},"cell_type":"code","source":"tokenize.fit_on_texts(train_text) # fit tokenizer to our training text data\nx_train = tokenize.texts_to_matrix(train_text)\nx_test = tokenize.texts_to_matrix(test_text)","execution_count":null,"outputs":[]},{"metadata":{"id":"lwVzFlWb7vZb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"40c75810-86da-4cde-dc41-ee74df6f1057","executionInfo":{"status":"ok","timestamp":1529968421345,"user_tz":240,"elapsed":224,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"da89fd94cb271dbe37b2deaf020a1992b15173f3"},"cell_type":"code","source":"# Use sklearn utility to convert label strings to numbered index\nencoder = LabelEncoder()\nencoder.fit(train_cat)\ny_train = encoder.transform(train_cat)\ny_test = encoder.transform(test_cat)","execution_count":null,"outputs":[]},{"metadata":{"id":"3bFkgysv7vZf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"524bd41b-9f55-43f8-9f63-f5d2ba3d4e3e","executionInfo":{"status":"ok","timestamp":1529968446804,"user_tz":240,"elapsed":231,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"7086e7934f8adeabc505aafa8a745f2fb00f2c7c"},"cell_type":"code","source":"# Converts the labels to a one-hot representation\nnum_classes = np.max(y_train) + 1\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","execution_count":null,"outputs":[]},{"metadata":{"id":"nbgyZpkn7vZi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":87},"outputId":"c2aaa800-ae4f-4b5f-d86a-8a1782808527","executionInfo":{"status":"ok","timestamp":1529968467789,"user_tz":240,"elapsed":329,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"76a85d88ebadf911ad3b8acbadea12b6feb8d943"},"cell_type":"code","source":"# Inspect the dimenstions of our training and test data (this is helpful to debug)\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\nprint('y_train shape:', y_train.shape)\nprint('y_test shape:', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"ms0L4rJidWRh","colab_type":"text","_uuid":"5838e4d6eb5f04b731d73507ad74c424cbc61e89"},"cell_type":"markdown","source":"## Train the model\n\nBuild the model using Keras layers and hyperparameters of your choosing. Then call `model.fit()`"},{"metadata":{"id":"Z3MmdGtx7vZl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"d6a745be-61fb-46ee-c791-29ca80140bca","executionInfo":{"status":"ok","timestamp":1529968784862,"user_tz":240,"elapsed":221,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"337b7d1e899297a868bb9b5a1eae4c4fb246c623"},"cell_type":"code","source":"# This model trains very quickly and 2 epochs are already more than enough\n# Training for more epochs will likely lead to overfitting on this dataset\n# You can try tweaking these hyperparamaters when using this model with your own data\nbatch_size = 32\nepochs = 2\ndrop_ratio = 0.5","execution_count":null,"outputs":[]},{"metadata":{"id":"VT6WEGF-7vZq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"9af614ad-0dd9-43c3-c3a1-225a7cbab986","executionInfo":{"status":"ok","timestamp":1529968787034,"user_tz":240,"elapsed":262,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"a1bbb4b632904850c9028433065f18825ab35d40"},"cell_type":"code","source":"# Build the model\nmodel = models.Sequential()\nmodel.add(layers.Dense(512, input_shape=(max_words,)))\nmodel.add(layers.Activation('relu'))\n# model.add(layers.Dropout(drop_ratio))\nmodel.add(layers.Dense(num_classes))\nmodel.add(layers.Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"aZi3ZHVn7vZt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":122},"outputId":"2a284ea1-dde6-45a0-842c-823d826a2f81","executionInfo":{"status":"ok","timestamp":1529968901259,"user_tz":240,"elapsed":1436,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"7e47a98aa3fb3fac7d1a66f226dfdbd73f0200af"},"cell_type":"code","source":"# model.fit trains the model\n# The validation_split param tells Keras what % of our training data should be used in the validation set\n# You can see the validation loss decreasing slowly when you run this\n# Because val_loss is no longer decreasing we stop training to prevent overfitting\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"id":"KZ-IXqRtdip6","colab_type":"text","_uuid":"43061a58c33a5d5b9a7667cf2dc07e776362cac9"},"cell_type":"markdown","source":"## Evaluate the model\nEvaluation is easy. Just call `model.evaluate()`."},{"metadata":{"id":"Rp7qGXOI7vZx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":68},"outputId":"3f97957f-3961-4342-a76b-112069b139ee","executionInfo":{"status":"ok","timestamp":1529968989028,"user_tz":240,"elapsed":256,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"cbc23de6b6ff62f33a9174dd64a941097672f3be"},"cell_type":"code","source":"# Evaluate the accuracy of our trained model\nscore = model.evaluate(x_test, y_test,\n                       batch_size=batch_size, verbose=1)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"id":"28xNG3mVeFIT","colab_type":"text","_uuid":"7f2b44f49bbcdaabad53a3fadb12a92722d65aaf"},"cell_type":"markdown","source":"## Hyperparameter tuning"},{"metadata":{"id":"YxoYLyHzeHPu","colab_type":"text","_uuid":"5e57f531af533325c1184bd0bcf1ff6cf4edc4d0"},"cell_type":"markdown","source":"This is a good time to go back and tweak some parameters such as `epoch`, `batch size`, `dropout ratio`, network structure, activation function, and others, to see if you can improve the accuracy.\n\nIn this particular case, to make it more challenging, I recommend reducing the max words of the call to `keras.preprocessing.text.Tokenizer`. This will reduce the number of words for each input sample, thus making it more challenging to accurately predict the category. (Notice that not all hyperparameters are necessarily inside the model. This is one such example.)\n\nThe default was up to 1000 words per article. See what happens when you reduce that number to 200 words, or 50 words, or even fewer. As the evaluation accuracy drops, the effects of your hyperparameter tuning will be more pronounced, with successful adjustments making meaningful improvements to the model performance.\n\nTo make this process easier to manage, I've encapulated the model definition and training and evaluation calls into one function call. You can add additional parameters as needed."},{"metadata":{"id":"QaOlQpLteGr8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":false,"collapsed":true,"_uuid":"bccfaad25ec2a6db799d5276bcdbc7993a1179ad"},"cell_type":"code","source":"def run_experiment(batch_size, epochs, drop_ratio):\n  print('batch size: {}, epochs: {}, drop_ratio: {}'.format(\n      batch_size, epochs, drop_ratio))\n  model = models.Sequential()\n  model.add(layers.Dense(512, input_shape=(max_words,)))\n  model.add(layers.Activation('relu'))\n  model.add(layers.Dropout(drop_ratio))\n  model.add(layers.Dense(num_classes))\n  model.add(layers.Activation('softmax'))\n\n  model.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['accuracy'])\n  history = model.fit(x_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=0,\n                    validation_split=0.1)\n  score = model.evaluate(x_test, y_test,\n                       batch_size=batch_size, verbose=0)\n  print('\\tTest loss:', score[0])\n  print('\\tTest accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"id":"pf1q6A6RfUOA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":67},"outputId":"f116fdb9-27fa-4a59-dcb4-2c40f77dbc34","executionInfo":{"status":"ok","timestamp":1528446977868,"user_tz":240,"elapsed":3431,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"f75ddec1c39edbd391edc2be623361c6b45fc48d"},"cell_type":"code","source":"batch_size = 16\nepochs = 4\ndrop_ratio = 0.4\nrun_experiment(batch_size, epochs, drop_ratio)","execution_count":null,"outputs":[]},{"metadata":{"id":"7X5sF8ZtgFRY","colab_type":"text","_uuid":"9e0aa1e7f4e713903b23dbf567c3d035511924e8"},"cell_type":"markdown","source":"###Hyperparameter Search\n\nYou can also automate this process using for-loops and more sophiscated methods of deciding which combinations of hyperparameter values to try out.\n\nExhaustive search is generally not the most elegant way, this is mostly just for illustrative purposes."},{"metadata":{"id":"fM6eCxpDf-hO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1378},"outputId":"1eb2d479-9e5b-47c5-d0fe-59afc41d1eb6","executionInfo":{"status":"ok","timestamp":1528447417461,"user_tz":240,"elapsed":148484,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"7cd75fbb89b5c79cc7dea56dc8499ce25604b9a0"},"cell_type":"code","source":"# Note: The data processed for this output had the max text length set to 400.\n# for batch_size in range(10,31,10):\n#   for epochs in range(3,15,5):\n#     for drop_ratio in np.linspace(0.1, 0.5, 3):\n#       run_experiment(batch_size, epochs, drop_ratio)","execution_count":null,"outputs":[]},{"metadata":{"id":"5Kwg1HISdvbJ","colab_type":"text","_uuid":"5ebd9f0d1120bb2ac6a65b9239f84431bdc1b181"},"cell_type":"markdown","source":"## Make some predictions\nTake some samples from the test dataset and inspect some individual predictions, to ensure that things are sensible.\n"},{"metadata":{"id":"cZX08a8b7vZz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":689},"outputId":"a424c2e3-7d17-4bc8-9d66-45e5b5e55c25","executionInfo":{"status":"ok","timestamp":1528444366463,"user_tz":240,"elapsed":247,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"92df624844b469e2464738e1538ec2688c29c8b8"},"cell_type":"code","source":"# Here's how to generate a prediction on individual examples\ntext_labels = encoder.classes_ \n\nfor i in range(10):\n    prediction = model.predict(np.array([x_test[i]]))\n    predicted_label = text_labels[np.argmax(prediction)]\n    print(test_text.iloc[i][:50], \"...\")\n    print('Actual label:' + test_cat.iloc[i])\n    print(\"Predicted label: \" + predicted_label + \"\\n\")  ","execution_count":null,"outputs":[]},{"metadata":{"id":"9fVPKqatd4wT","colab_type":"text","_uuid":"cffc52f2cf377c9e3b446e8b60c9f1616f5859df"},"cell_type":"markdown","source":"## (optional) Extra extra! Visualize the confusion matrix\nThis can help identify which areas were a challenge to get right, if the model is performing poorly."},{"metadata":{"id":"5iwjnls-7vZ6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":false,"collapsed":true,"_uuid":"f0ac86d025cc57f48849d33f664bc6f355f196a2"},"cell_type":"code","source":"y_softmax = model.predict(x_test)\n\ny_test_1d = []\ny_pred_1d = []\n\nfor i in range(len(y_test)):\n    probs = y_test[i]\n    index_arr = np.nonzero(probs)\n    one_hot_index = index_arr[0].item(0)\n    y_test_1d.append(one_hot_index)\n\nfor i in range(0, len(y_softmax)):\n    probs = y_softmax[i]\n    predicted_index = np.argmax(probs)\n    y_pred_1d.append(predicted_index)","execution_count":null,"outputs":[]},{"metadata":{"id":"7ljbbrdu7vZ9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":false,"collapsed":true,"_uuid":"a289402f4815e8bc322b12194c1b1b3acdd80931"},"cell_type":"code","source":"# This utility function is from the sklearn docs: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=30)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45, fontsize=22)\n    plt.yticks(tick_marks, classes, fontsize=22)\n\n    fmt = '.2f'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label', fontsize=25)\n    plt.xlabel('Predicted label', fontsize=25)","execution_count":null,"outputs":[]},{"metadata":{"id":"53JHPfCB7vZ_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1295},"outputId":"9a940bfd-04a2-4ed2-cd7a-9ae4d2521941","executionInfo":{"status":"ok","timestamp":1528444377842,"user_tz":240,"elapsed":1000,"user":{"displayName":"Yufeng Guo","photoUrl":"//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg","userId":"112030861868146149303"}},"trusted":false,"collapsed":true,"_uuid":"9e0238c7efd8b90aa654f67c258c6513c99fc9ef"},"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\nplt.figure(figsize=(24,20))\nplot_confusion_matrix(cnf_matrix, classes=text_labels, title=\"Confusion matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"0H1KIsy77vaC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"trusted":false,"collapsed":true,"_uuid":"6c286179093db65f3c0638a92bb5823f46544098"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Published BBC text BOW","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1IlP-4XDM1_5NRdR5g_6DbIT-YvdwKGvn","timestamp":1528444855450}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}